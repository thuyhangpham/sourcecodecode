{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1 Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line)\n",
    "\n",
    "def getDF(path):\n",
    "    df = [d for d in parse(path)]\n",
    "    return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/All_Beauty.json'\n",
    "df_all_beauty = getDF(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 19, 2015</td>\n",
       "      <td>A1V6B6TNIC10QE</td>\n",
       "      <td>0143026860</td>\n",
       "      <td>theodore j bigham</td>\n",
       "      <td>great</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1424304000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>12 18, 2014</td>\n",
       "      <td>A2F5GHSXFQ0W6J</td>\n",
       "      <td>0143026860</td>\n",
       "      <td>Mary K. Byke</td>\n",
       "      <td>My  husband wanted to reading about the Negro ...</td>\n",
       "      <td>... to reading about the Negro Baseball and th...</td>\n",
       "      <td>1418860800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>08 10, 2014</td>\n",
       "      <td>A1572GUYS7DGSR</td>\n",
       "      <td>0143026860</td>\n",
       "      <td>David G</td>\n",
       "      <td>This book was very informative, covering all a...</td>\n",
       "      <td>Worth the Read</td>\n",
       "      <td>1407628800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 11, 2013</td>\n",
       "      <td>A1PSGLFK1NSVO</td>\n",
       "      <td>0143026860</td>\n",
       "      <td>TamB</td>\n",
       "      <td>I am already a baseball fan and knew a bit abo...</td>\n",
       "      <td>Good Read</td>\n",
       "      <td>1362960000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>12 25, 2011</td>\n",
       "      <td>A6IKXKZMTKGSC</td>\n",
       "      <td>0143026860</td>\n",
       "      <td>shoecanary</td>\n",
       "      <td>This was a good story of the Black leagues. I ...</td>\n",
       "      <td>More than facts, a good story read!</td>\n",
       "      <td>1324771200</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371340</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 20, 2017</td>\n",
       "      <td>A202DCI7TV1022</td>\n",
       "      <td>B01HJEGTYK</td>\n",
       "      <td>Sam</td>\n",
       "      <td>It was awful. It was super frizzy and I tried ...</td>\n",
       "      <td>It was super frizzy and I tried to comb it and...</td>\n",
       "      <td>1500508800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371341</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 16, 2017</td>\n",
       "      <td>A3FSOR5IJOFIBE</td>\n",
       "      <td>B01HJEGTYK</td>\n",
       "      <td>TYW</td>\n",
       "      <td>I was skeptical about buying this.  Worried it...</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>1489622400</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371342</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 1, 2017</td>\n",
       "      <td>A1B5DK6CTP2P24</td>\n",
       "      <td>B01HJEGTYK</td>\n",
       "      <td>Norma Jennings</td>\n",
       "      <td>Makes me look good fast.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1488326400</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371343</th>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 21, 2017</td>\n",
       "      <td>A23OUYS5IRMJS9</td>\n",
       "      <td>B01HJEGTYK</td>\n",
       "      <td>Lee</td>\n",
       "      <td>Way lighter than photo\\nNot mix blend of color...</td>\n",
       "      <td>Ok but color way off and volume as well</td>\n",
       "      <td>1487635200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371344</th>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>12 15, 2016</td>\n",
       "      <td>A24KQ9RVU81L87</td>\n",
       "      <td>B01HJEGTYK</td>\n",
       "      <td>Season341</td>\n",
       "      <td>No return instructions/phone # in packaging.  ...</td>\n",
       "      <td>Might return for a replacement if I could.</td>\n",
       "      <td>1481760000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>371345 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0           1.0      True  02 19, 2015  A1V6B6TNIC10QE  0143026860   \n",
       "1           4.0      True  12 18, 2014  A2F5GHSXFQ0W6J  0143026860   \n",
       "2           4.0      True  08 10, 2014  A1572GUYS7DGSR  0143026860   \n",
       "3           5.0      True  03 11, 2013   A1PSGLFK1NSVO  0143026860   \n",
       "4           5.0      True  12 25, 2011   A6IKXKZMTKGSC  0143026860   \n",
       "...         ...       ...          ...             ...         ...   \n",
       "371340      1.0      True  07 20, 2017  A202DCI7TV1022  B01HJEGTYK   \n",
       "371341      5.0      True  03 16, 2017  A3FSOR5IJOFIBE  B01HJEGTYK   \n",
       "371342      5.0      True   03 1, 2017  A1B5DK6CTP2P24  B01HJEGTYK   \n",
       "371343      2.0      True  02 21, 2017  A23OUYS5IRMJS9  B01HJEGTYK   \n",
       "371344      2.0      True  12 15, 2016  A24KQ9RVU81L87  B01HJEGTYK   \n",
       "\n",
       "             reviewerName                                         reviewText  \\\n",
       "0       theodore j bigham                                              great   \n",
       "1            Mary K. Byke  My  husband wanted to reading about the Negro ...   \n",
       "2                 David G  This book was very informative, covering all a...   \n",
       "3                    TamB  I am already a baseball fan and knew a bit abo...   \n",
       "4              shoecanary  This was a good story of the Black leagues. I ...   \n",
       "...                   ...                                                ...   \n",
       "371340                Sam  It was awful. It was super frizzy and I tried ...   \n",
       "371341                TYW  I was skeptical about buying this.  Worried it...   \n",
       "371342     Norma Jennings                           Makes me look good fast.   \n",
       "371343                Lee  Way lighter than photo\\nNot mix blend of color...   \n",
       "371344          Season341  No return instructions/phone # in packaging.  ...   \n",
       "\n",
       "                                                  summary  unixReviewTime  \\\n",
       "0                                                One Star      1424304000   \n",
       "1       ... to reading about the Negro Baseball and th...      1418860800   \n",
       "2                                          Worth the Read      1407628800   \n",
       "3                                               Good Read      1362960000   \n",
       "4                     More than facts, a good story read!      1324771200   \n",
       "...                                                   ...             ...   \n",
       "371340  It was super frizzy and I tried to comb it and...      1500508800   \n",
       "371341                                            Awesome      1489622400   \n",
       "371342                                         Five Stars      1488326400   \n",
       "371343            Ok but color way off and volume as well      1487635200   \n",
       "371344         Might return for a replacement if I could.      1481760000   \n",
       "\n",
       "       vote style image  \n",
       "0       NaN   NaN   NaN  \n",
       "1       NaN   NaN   NaN  \n",
       "2       NaN   NaN   NaN  \n",
       "3       NaN   NaN   NaN  \n",
       "4         5   NaN   NaN  \n",
       "...     ...   ...   ...  \n",
       "371340  NaN   NaN   NaN  \n",
       "371341   34   NaN   NaN  \n",
       "371342   46   NaN   NaN  \n",
       "371343  NaN   NaN   NaN  \n",
       "371344  NaN   NaN   NaN  \n",
       "\n",
       "[371345 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_beauty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path1 = './data/AMAZON_FASHION.json'\n",
    "file_path2 = './data/Appliances.json'\n",
    "\n",
    "df_amazon_fashion = getDF(file_path1)\n",
    "df_appliances = getDF(file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1V6B6TNIC10QE</td>\n",
       "      <td>0143026860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1424304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2F5GHSXFQ0W6J</td>\n",
       "      <td>0143026860</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1418860800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1572GUYS7DGSR</td>\n",
       "      <td>0143026860</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1407628800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1PSGLFK1NSVO</td>\n",
       "      <td>0143026860</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1362960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A6IKXKZMTKGSC</td>\n",
       "      <td>0143026860</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1324771200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602772</th>\n",
       "      <td>A24A9P4F2SLTK5</td>\n",
       "      <td>B01HJH2PY0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1502323200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602773</th>\n",
       "      <td>A2JCB4KHBWEELW</td>\n",
       "      <td>B01HJHHEA0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1533081600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602774</th>\n",
       "      <td>A1LDYYVTLPP2Z5</td>\n",
       "      <td>B01HJHHEA0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1523577600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602775</th>\n",
       "      <td>AP1M5O06IOYZ7</td>\n",
       "      <td>B01HJH92JQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1521763200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602776</th>\n",
       "      <td>A1BU98NV4Y0P9K</td>\n",
       "      <td>B01HJH92JQ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1515369600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1857758 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin  overall  unixReviewTime\n",
       "0       A1V6B6TNIC10QE  0143026860      1.0      1424304000\n",
       "1       A2F5GHSXFQ0W6J  0143026860      4.0      1418860800\n",
       "2       A1572GUYS7DGSR  0143026860      4.0      1407628800\n",
       "3        A1PSGLFK1NSVO  0143026860      5.0      1362960000\n",
       "4        A6IKXKZMTKGSC  0143026860      5.0      1324771200\n",
       "...                ...         ...      ...             ...\n",
       "602772  A24A9P4F2SLTK5  B01HJH2PY0      5.0      1502323200\n",
       "602773  A2JCB4KHBWEELW  B01HJHHEA0      2.0      1533081600\n",
       "602774  A1LDYYVTLPP2Z5  B01HJHHEA0      5.0      1523577600\n",
       "602775   AP1M5O06IOYZ7  B01HJH92JQ      1.0      1521763200\n",
       "602776  A1BU98NV4Y0P9K  B01HJH92JQ      3.0      1515369600\n",
       "\n",
       "[1857758 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_selected = df_all_beauty[['reviewerID', 'asin', 'overall', 'unixReviewTime']]\n",
    "df2_selected = df_amazon_fashion[['reviewerID', 'asin', 'overall', 'unixReviewTime']]\n",
    "df3_selected = df_appliances[['reviewerID', 'asin', 'overall', 'unixReviewTime']]\n",
    "\n",
    "df_combined = pd.concat([df1_selected, df2_selected, df3_selected], axis=0)\n",
    "\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('df_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_csv('df_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2 Transform data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning the dataset from duplicates, missing overall will be set to 0, changing the unix time format to UTC datetime format reformatting the ID to simple unique integer values and finally, transforming of the shape of the dataset to 2D matrix (RM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Number of duplicate rows: 28561\n",
      "\n",
      "Duplicate values per column:\n",
      "overall           1857753\n",
      "unixReviewTime    1852343\n",
      "asin              1608731\n",
      "reviewerID         340802\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra các giá trị bị thiếu\n",
    "missing_summary = df_combined.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_summary[missing_summary > 0])\n",
    "\n",
    "# Kiểm tra trùng lặp toàn bộ dòng\n",
    "duplicates = df_combined.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Kiểm tra trùng lặp cho từng cột\n",
    "duplicate_columns = {}\n",
    "for col in df_combined.columns:\n",
    "    duplicate_columns[col] = df_combined[col].duplicated().sum()\n",
    "\n",
    "print(\"\\nDuplicate values per column:\")\n",
    "print(pd.Series(duplicate_columns).sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "df_combined = df_combined.drop_duplicates()\n",
    "duplicates = df_combined.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>AD80MGOY5CJZ4</td>\n",
       "      <td>1620213982</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1451692800</td>\n",
       "      <td>2016-01-02 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>AD80MGOY5CJZ4</td>\n",
       "      <td>1620213982</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1422662400</td>\n",
       "      <td>2015-01-31 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6904</th>\n",
       "      <td>ACTVXNBEPLW2S</td>\n",
       "      <td>B000052YAN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1422144000</td>\n",
       "      <td>2015-01-25 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6905</th>\n",
       "      <td>ACTVXNBEPLW2S</td>\n",
       "      <td>B000052YAN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1422144000</td>\n",
       "      <td>2015-01-25 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6941</th>\n",
       "      <td>A2CTM1BYAXTYLX</td>\n",
       "      <td>B0000530HU</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1243987200</td>\n",
       "      <td>2009-06-03 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830861</th>\n",
       "      <td>AAXZWNM0SGJ6V</td>\n",
       "      <td>B00W0WXHCO</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1531699200</td>\n",
       "      <td>2018-07-16 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832245</th>\n",
       "      <td>A33E3AB96IZHE9</td>\n",
       "      <td>B00X9H5S62</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1445212800</td>\n",
       "      <td>2015-10-19 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832246</th>\n",
       "      <td>A33E3AB96IZHE9</td>\n",
       "      <td>B00X9H5S62</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1439942400</td>\n",
       "      <td>2015-08-19 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841744</th>\n",
       "      <td>A1HT6VX64S9NE8</td>\n",
       "      <td>B015HUNWQG</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1517097600</td>\n",
       "      <td>2018-01-28 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854036</th>\n",
       "      <td>A30TT3NLCYM8MF</td>\n",
       "      <td>B01F2D4AS2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1490918400</td>\n",
       "      <td>2017-03-31 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57791 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             reviewerID        asin  overall  unixReviewTime  \\\n",
       "2352      AD80MGOY5CJZ4  1620213982      5.0      1451692800   \n",
       "4017      AD80MGOY5CJZ4  1620213982      5.0      1422662400   \n",
       "6904      ACTVXNBEPLW2S  B000052YAN      4.0      1422144000   \n",
       "6905      ACTVXNBEPLW2S  B000052YAN      4.0      1422144000   \n",
       "6941     A2CTM1BYAXTYLX  B0000530HU      5.0      1243987200   \n",
       "...                 ...         ...      ...             ...   \n",
       "1830861   AAXZWNM0SGJ6V  B00W0WXHCO      4.0      1531699200   \n",
       "1832245  A33E3AB96IZHE9  B00X9H5S62      3.0      1445212800   \n",
       "1832246  A33E3AB96IZHE9  B00X9H5S62      2.0      1439942400   \n",
       "1841744  A1HT6VX64S9NE8  B015HUNWQG      5.0      1517097600   \n",
       "1854036  A30TT3NLCYM8MF  B01F2D4AS2      5.0      1490918400   \n",
       "\n",
       "                       reviewTime  \n",
       "2352    2016-01-02 00:00:00+00:00  \n",
       "4017    2015-01-31 00:00:00+00:00  \n",
       "6904    2015-01-25 00:00:00+00:00  \n",
       "6905    2015-01-25 00:00:00+00:00  \n",
       "6941    2009-06-03 00:00:00+00:00  \n",
       "...                           ...  \n",
       "1830861 2018-07-16 00:00:00+00:00  \n",
       "1832245 2015-10-19 00:00:00+00:00  \n",
       "1832246 2015-08-19 00:00:00+00:00  \n",
       "1841744 2018-01-28 00:00:00+00:00  \n",
       "1854036 2017-03-31 00:00:00+00:00  \n",
       "\n",
       "[57791 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicate reviews by same user for the same product\n",
    "# Chuyển đổi cột unixReviewTime từ Unix timestamp sang datetime theo UTC\n",
    "df_combined['reviewTime'] = pd.to_datetime(df_combined['unixReviewTime'], unit='s', utc=True)\n",
    "duplicate_reviews = df_combined[df_combined.duplicated(subset=['reviewerID', 'asin'], keep=False)]\n",
    "duplicate_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sắp xếp DataFrame theo cột 'time' giảm dần\n",
    "df_combined = df_combined.sort_values(by=['reviewerID', 'asin', 'reviewTime'], ascending=[True, True, False])\n",
    "\n",
    "# Giữ lại dòng đầu tiên (gần đây nhất) cho mỗi cặp reviewerID và asin\n",
    "df_combined = df_combined.drop_duplicates(subset=['reviewerID', 'asin'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1593537</th>\n",
       "      <td>A0001528BGUBOEVR6T5U</td>\n",
       "      <td>B00MVVITWC</td>\n",
       "      <td>5.0</td>\n",
       "      <td>u1</td>\n",
       "      <td>i91564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382775</th>\n",
       "      <td>A00032921HLX2KJJVXRS</td>\n",
       "      <td>B0045LLC7K</td>\n",
       "      <td>5.0</td>\n",
       "      <td>u2</td>\n",
       "      <td>i17567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568898</th>\n",
       "      <td>A0007604Q2582KFW7N4B</td>\n",
       "      <td>B00L8J2RF8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>u3</td>\n",
       "      <td>i81636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785338</th>\n",
       "      <td>A00086729ZDSXGG2E481</td>\n",
       "      <td>B00E1IUTOY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>u4</td>\n",
       "      <td>i48836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708824</th>\n",
       "      <td>A0009408W4B7B4DKF0XN</td>\n",
       "      <td>B01DO0ZR50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>u5</td>\n",
       "      <td>i219479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250877</th>\n",
       "      <td>AZZZ5UJWUVCYZ</td>\n",
       "      <td>B01FNJ9MOW</td>\n",
       "      <td>5.0</td>\n",
       "      <td>u1516952</td>\n",
       "      <td>i234681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463413</th>\n",
       "      <td>AZZZGPFIX5NEY</td>\n",
       "      <td>B0097C43BO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>u1516953</td>\n",
       "      <td>i33551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508737</th>\n",
       "      <td>AZZZMCJO078D2</td>\n",
       "      <td>B00EONSCKO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>u1516954</td>\n",
       "      <td>i52115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006582</th>\n",
       "      <td>AZZZU2YUCMUUW</td>\n",
       "      <td>B00WQEPQ20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>u1516955</td>\n",
       "      <td>i132125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561061</th>\n",
       "      <td>AZZZY1W55XHZR</td>\n",
       "      <td>B00JR947EU</td>\n",
       "      <td>3.0</td>\n",
       "      <td>u1516956</td>\n",
       "      <td>i73134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1827570 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   reviewerID        asin  overall    userID   itemID\n",
       "1593537  A0001528BGUBOEVR6T5U  B00MVVITWC      5.0        u1   i91564\n",
       "1382775  A00032921HLX2KJJVXRS  B0045LLC7K      5.0        u2   i17567\n",
       "568898   A0007604Q2582KFW7N4B  B00L8J2RF8      5.0        u3   i81636\n",
       "1785338  A00086729ZDSXGG2E481  B00E1IUTOY      1.0        u4   i48836\n",
       "1708824  A0009408W4B7B4DKF0XN  B01DO0ZR50      1.0        u5  i219479\n",
       "...                       ...         ...      ...       ...      ...\n",
       "250877          AZZZ5UJWUVCYZ  B01FNJ9MOW      5.0  u1516952  i234681\n",
       "1463413         AZZZGPFIX5NEY  B0097C43BO      1.0  u1516953   i33551\n",
       "508737          AZZZMCJO078D2  B00EONSCKO      2.0  u1516954   i52115\n",
       "1006582         AZZZU2YUCMUUW  B00WQEPQ20      5.0  u1516955  i132125\n",
       "1561061         AZZZY1W55XHZR  B00JR947EU      3.0  u1516956   i73134\n",
       "\n",
       "[1827570 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed = df_combined.drop(columns=['unixReviewTime', 'reviewTime'])\n",
    "# Tạo cột mã hóa cho `reviewerID` và `asin`\n",
    "df_preprocessed['userID'] = 'u' + (df_combined['reviewerID'].astype('category').cat.codes + 1).astype(str)\n",
    "df_preprocessed['itemID'] = 'i' + (df_combined['asin'].astype('category').cat.codes + 1).astype(str)\n",
    "\n",
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed.to_csv('df_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = pd.read_csv('df_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewerID    0\n",
      "asin          0\n",
      "overall       0\n",
      "userID        0\n",
      "itemID        0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "Duplicate values per column:\n",
      "overall       1827565\n",
      "asin          1578543\n",
      "itemID        1578543\n",
      "reviewerID     310614\n",
      "userID         310614\n",
      "dtype: int64\n",
      "reviewerID    0\n",
      "asin          0\n",
      "overall       0\n",
      "userID        0\n",
      "itemID        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_preprocessed.isnull().sum())\n",
    "\n",
    "# Kiểm tra trùng lặp toàn bộ dòng\n",
    "duplicates = df_preprocessed.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Kiểm tra trùng lặp cho từng cột\n",
    "duplicate_columns = {}\n",
    "for col in df_preprocessed.columns:\n",
    "    duplicate_columns[col] = df_preprocessed[col].duplicated().sum()\n",
    "\n",
    "print(\"\\nDuplicate values per column:\")\n",
    "print(pd.Series(duplicate_columns).sort_values(ascending=False))\n",
    "\n",
    "print(df_preprocessed.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1516956\n",
      "249027\n"
     ]
    }
   ],
   "source": [
    "print(df_preprocessed['userID'].nunique())\n",
    "print(df_preprocessed['itemID'].nunique()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sovle large scale of input data problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix, csr_matrix, save_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparse_rating_matrix(df):\n",
    "    \"\"\"\n",
    "    Tạo ma trận đánh giá thưa từ DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame chứa dữ liệu userID, itemID, overall.\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: Ma trận đánh giá thưa.\n",
    "        dict: Ánh xạ từ user id gốc sang index.\n",
    "        dict: Ánh xạ từ item id gốc sang index.\n",
    "    \"\"\"\n",
    "    # 1. Tạo mapping\n",
    "    unique_users = df['userID'].unique()\n",
    "    unique_items = df['itemID'].unique()\n",
    "    user_mapping = {user_id: index for index, user_id in enumerate(unique_users)}\n",
    "    item_mapping = {item_id: index for index, item_id in enumerate(unique_items)}\n",
    "\n",
    "    df['user_index'] = df['userID'].map(user_mapping)\n",
    "    df['item_index'] = df['itemID'].map(item_mapping)\n",
    "\n",
    "    # 2. Tạo sparse matrix\n",
    "    num_users = len(unique_users)\n",
    "    num_items = len(unique_items)\n",
    "    ratings = df['overall'].values\n",
    "    row_indices = df['user_index'].values\n",
    "    col_indices = df['item_index'].values\n",
    "    rating_matrix = csr_matrix((ratings, (row_indices, col_indices)), shape=(num_users, num_items))\n",
    "\n",
    "    return rating_matrix, user_mapping, item_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix, user_mapping, item_mapping = create_sparse_rating_matrix(df_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3 Similarity calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sparse_matrix(filename, matrix):\n",
    "    \"\"\"Helper function to save sparse matrix\"\"\"\n",
    "    csr_matrix = matrix.tocsr()\n",
    "    save_npz(filename, csr_matrix)\n",
    "\n",
    "def load_sparse_matrix(filename):\n",
    "    \"\"\"Helper function to load sparse matrix\"\"\"\n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                     shape=loader['shape'])\n",
    "\n",
    "def calculate_similarity_batch(rating_matrix, batch_size=1000, similarity_metric='cosine', save_path=None):\n",
    "    \"\"\"\n",
    "    Calculates user similarity matrix using batch processing to handle large datasets.\n",
    "    \n",
    "    Args:\n",
    "        rating_matrix (csr_matrix): Sparse user-item rating matrix\n",
    "        batch_size (int): Size of batches for processing\n",
    "        similarity_metric (str): Similarity metric ('cosine', 'pearson', 'jaccard', 'spearman', 'kendall')\n",
    "        save_path (str): Optional path to save intermediate results\n",
    "        \n",
    "    Returns:\n",
    "        scipy.sparse.lil_matrix: Sparse similarity matrix\n",
    "    \"\"\"\n",
    "    num_users = rating_matrix.shape[0]\n",
    "    similarity_matrix = lil_matrix((num_users, num_users))\n",
    "    \n",
    "    # Create save directory if needed\n",
    "    if save_path and not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # Calculate number of batches\n",
    "    num_batches = (num_users + batch_size - 1) // batch_size\n",
    "    \n",
    "    # Process batches with progress bar\n",
    "    for i in tqdm(range(0, num_users, batch_size)):\n",
    "        batch_end_i = min(i + batch_size, num_users)\n",
    "        batch_i = rating_matrix[i:batch_end_i]\n",
    "        \n",
    "        for j in range(i, num_users, batch_size):\n",
    "            batch_end_j = min(j + batch_size, num_users)\n",
    "            batch_j = rating_matrix[j:batch_end_j]\n",
    "            \n",
    "            # Calculate similarities based on metric\n",
    "            if similarity_metric == 'cosine':\n",
    "                sim_batch = cosine_similarity(batch_i, batch_j)\n",
    "            else:\n",
    "                sim_batch = np.zeros((batch_end_i - i, batch_end_j - j))\n",
    "                \n",
    "                for bi in range(batch_end_i - i):\n",
    "                    for bj in range(batch_end_j - j):\n",
    "                        user1_ratings = batch_i[bi].toarray()[0]\n",
    "                        user2_ratings = batch_j[bj].toarray()[0]\n",
    "                        \n",
    "                        # Get common rated items\n",
    "                        mask = (user1_ratings != 0) & (user2_ratings != 0)\n",
    "                        ratings1 = user1_ratings[mask]\n",
    "                        ratings2 = user2_ratings[mask]\n",
    "                        \n",
    "                        if len(ratings1) > 1:\n",
    "                            if similarity_metric == 'pearson':\n",
    "                                sim = pearsonr(ratings1, ratings2)[0]\n",
    "                            elif similarity_metric == 'spearman':\n",
    "                                sim = spearmanr(ratings1, ratings2)[0]\n",
    "                            elif similarity_metric == 'kendall':\n",
    "                                sim = kendalltau(ratings1, ratings2)[0]\n",
    "                            elif similarity_metric == 'jaccard':\n",
    "                                set1 = set(np.nonzero(user1_ratings)[0])\n",
    "                                set2 = set(np.nonzero(user2_ratings)[0])\n",
    "                                sim = len(set1.intersection(set2)) / len(set1.union(set2)) if set1 or set2 else 0\n",
    "                            \n",
    "                            sim_batch[bi, bj] = 0 if np.isnan(sim) else sim\n",
    "            \n",
    "            # Update similarity matrix\n",
    "            similarity_matrix[i:batch_end_i, j:batch_end_j] = sim_batch\n",
    "            \n",
    "            # Mirror the matrix for symmetry (if not on diagonal)\n",
    "            if i != j:\n",
    "                similarity_matrix[j:batch_end_j, i:batch_end_i] = sim_batch.T\n",
    "            \n",
    "            # Save intermediate results if path provided\n",
    "            if save_path:\n",
    "                temp_file = os.path.join(save_path, f'sim_batch_{i}_{j}.npz')\n",
    "                save_sparse_matrix(temp_file, similarity_matrix)\n",
    "    \n",
    "    return similarity_matrix\n",
    "\n",
    "def save_sparse_matrix(filename, matrix):\n",
    "    \"\"\"Helper function to save sparse matrix\"\"\"\n",
    "    np.savez(filename, data=matrix.data, indices=matrix.indices,\n",
    "             indptr=matrix.indptr, shape=matrix.shape)\n",
    "\n",
    "def load_sparse_matrix(filename):\n",
    "    \"\"\"Helper function to load sparse matrix\"\"\"\n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                     shape=loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "SAVE_PATH = './similarity_matrices'  # Optional: create this directory first\n",
    "    \n",
    "# Create save directory if needed\n",
    "if SAVE_PATH and not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15170 [00:00<?, ?it/s]C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "  0%|          | 0/15170 [00:41<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'lil_matrix' object has no attribute 'indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pearson_sim \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_similarity_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrating_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msimilarity_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpearson\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./similarity_matrices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m user_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rating_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n\u001b[0;32m      9\u001b[0m pearson_sim_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     10\u001b[0m     pearson_sim\u001b[38;5;241m.\u001b[39mtoarray(),\n\u001b[0;32m     11\u001b[0m     index\u001b[38;5;241m=\u001b[39muser_ids,\n\u001b[0;32m     12\u001b[0m     columns\u001b[38;5;241m=\u001b[39muser_ids\n\u001b[0;32m     13\u001b[0m )\n",
      "Cell \u001b[1;32mIn[40], line 84\u001b[0m, in \u001b[0;36mcalculate_similarity_batch\u001b[1;34m(rating_matrix, batch_size, similarity_metric, save_path)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m save_path:\n\u001b[0;32m     83\u001b[0m             temp_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msim_batch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 84\u001b[0m             \u001b[43msave_sparse_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m similarity_matrix\n",
      "Cell \u001b[1;32mIn[40], line 90\u001b[0m, in \u001b[0;36msave_sparse_matrix\u001b[1;34m(filename, matrix)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_sparse_matrix\u001b[39m(filename, matrix):\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to save sparse matrix\"\"\"\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m     np\u001b[38;5;241m.\u001b[39msavez(filename, data\u001b[38;5;241m=\u001b[39mmatrix\u001b[38;5;241m.\u001b[39mdata, indices\u001b[38;5;241m=\u001b[39m\u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m,\n\u001b[0;32m     91\u001b[0m              indptr\u001b[38;5;241m=\u001b[39mmatrix\u001b[38;5;241m.\u001b[39mindptr, shape\u001b[38;5;241m=\u001b[39mmatrix\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'lil_matrix' object has no attribute 'indices'"
     ]
    }
   ],
   "source": [
    "pearson_sim = calculate_similarity_batch(\n",
    "    rating_matrix,\n",
    "    batch_size=100,\n",
    "    similarity_metric='pearson',\n",
    "    save_path='./similarity_matrices'\n",
    ")\n",
    "\n",
    "user_ids = [f'u{i+1}' for i in range(rating_matrix.shape[0])]\n",
    "pearson_sim_df = pd.DataFrame(\n",
    "    pearson_sim.toarray(),\n",
    "    index=user_ids,\n",
    "    columns=user_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4 OCA Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OCA(SM):\n",
    "    \"\"\"Thực hiện thuật toán Ordered Clustering.\"\"\"\n",
    "    clusters = {}\n",
    "\n",
    "    # Duyệt qua các cặp user trong ma trận tương đồng\n",
    "    for i, user_i in enumerate(SM.index):\n",
    "        for j, user_j in enumerate(SM.columns):\n",
    "            if i >= j:\n",
    "                continue\n",
    "\n",
    "            similarity = SM.iloc[i, j]\n",
    "            \n",
    "            if similarity > 0:\n",
    "                # Tạo cluster mới nếu chưa có, key là giá trị tương đồng cụ thể\n",
    "                if similarity not in clusters:\n",
    "                     clusters[similarity] = []\n",
    "                \n",
    "                # Thêm user vào cluster, đảm bảo thứ tự dựa trên độ tương đồng\n",
    "                if not clusters[similarity]:\n",
    "                    clusters[similarity].extend([user_i,user_j])\n",
    "                else:\n",
    "                    user_i_index = -1\n",
    "                    user_j_index = -1\n",
    "                    \n",
    "                    if user_i in clusters[similarity]:\n",
    "                       user_i_index = clusters[similarity].index(user_i)\n",
    "                    if user_j in clusters[similarity]:\n",
    "                      user_j_index = clusters[similarity].index(user_j)\n",
    "                                  \n",
    "                    if user_i_index == -1 and user_j_index == -1:\n",
    "                        inserted = False\n",
    "                        for k in range(len(clusters[similarity])):\n",
    "                            user_k = clusters[similarity][k]\n",
    "                            sim_ik = SM.iloc[i,SM.index.get_loc(user_k)]\n",
    "                            \n",
    "                            if sim_ik < similarity:\n",
    "                                clusters[similarity].insert(k,user_i)\n",
    "                                inserted = True\n",
    "                                break\n",
    "                                \n",
    "                        if not inserted:\n",
    "                            clusters[similarity].append(user_i)\n",
    "                          \n",
    "                        inserted = False\n",
    "                        for k in range(len(clusters[similarity])):\n",
    "                            user_k = clusters[similarity][k]\n",
    "                            sim_jk = SM.iloc[j,SM.index.get_loc(user_k)]\n",
    "                            \n",
    "                            if sim_jk < similarity:\n",
    "                                clusters[similarity].insert(k,user_j)\n",
    "                                inserted = True\n",
    "                                break\n",
    "                                \n",
    "                        if not inserted:\n",
    "                            clusters[similarity].append(user_j)\n",
    "                    elif user_i_index > -1 and user_j_index == -1:\n",
    "                        inserted = False\n",
    "                        for k in range(len(clusters[similarity])):\n",
    "                            user_k = clusters[similarity][k]\n",
    "                            sim_jk = SM.iloc[j,SM.index.get_loc(user_k)]\n",
    "                            \n",
    "                            if sim_jk < similarity:\n",
    "                                clusters[similarity].insert(k,user_j)\n",
    "                                inserted = True\n",
    "                                break\n",
    "                                \n",
    "                        if not inserted:\n",
    "                            clusters[similarity].append(user_j)\n",
    "                    elif user_i_index == -1 and user_j_index > -1:\n",
    "                       inserted = False\n",
    "                       for k in range(len(clusters[similarity])):\n",
    "                           user_k = clusters[similarity][k]\n",
    "                           sim_ik = SM.iloc[i,SM.index.get_loc(user_k)]\n",
    "                            \n",
    "                           if sim_ik < similarity:\n",
    "                               clusters[similarity].insert(k,user_i)\n",
    "                               inserted = True\n",
    "                               break\n",
    "                       if not inserted:\n",
    "                           clusters[similarity].append(user_i)\n",
    "\n",
    "    # Sắp xếp các cluster theo độ tương đồng giảm dần\n",
    "    sorted_clusters = sorted(clusters.items(), key=lambda item: item, reverse=True)\n",
    "    sorted_clusters_dict = {k: v for k, v in sorted_clusters}\n",
    "    return sorted_clusters_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
